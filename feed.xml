<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://cstheory-georgetown.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://cstheory-georgetown.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-16T20:06:45+00:00</updated><id>https://cstheory-georgetown.github.io/feed.xml</id><title type="html">Theory @ Georgetown</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">List Decoding of near optimal binary codes at Johnson Bound</title><link href="https://cstheory-georgetown.github.io/blog/2022/sourya-roy/" rel="alternate" type="text/html" title="List Decoding of near optimal binary codes at Johnson Bound"/><published>2022-12-02T15:59:00+00:00</published><updated>2022-12-02T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/sourya-roy</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/sourya-roy/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://sra2.github.io/souryar/">Sourya Roy</a> December 12, 2022.</p> <h3 id="abstract">Abstract</h3> <p>In his breakthrough work(STOC 2017), Ta-shma gave a binary code construction which nearly matches Gilbert-Varshamov bound in terms of rate-distance tradeoff. I will describe our recent work on list decoding this code upto the popular Johnson bound radius. Our algorithm is semi-definite programming hierarchy based and at the core of our analysis is an expander mixing lemma based recursive argument. This is a joint work with Silas Richelson.</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="Coding_theory"/><summary type="html"><![CDATA[Sourya Roy]]></summary></entry><entry><title type="html">Derandomization from Time-Space Tradeoffs</title><link href="https://cstheory-georgetown.github.io/blog/2022/oliver-korten/" rel="alternate" type="text/html" title="Derandomization from Time-Space Tradeoffs"/><published>2022-11-18T15:59:00+00:00</published><updated>2022-11-18T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/oliver-korten</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/oliver-korten/"><![CDATA[<h3 id="speaker">Speaker</h3> <p>[Oliver Korten] November 18, 2022.</p> <h3 id="abstract">Abstract</h3> <p>A recurring challenge in the theory of pseudorandomness and circuit complexity is the explicit construction of <code class="language-plaintext highlighter-rouge">incompressible strings,'' i.e. finite objects which lack a specific type of structure or simplicity. In most cases, there is an associated NP search problem which we call the</code>compression problem,’’ where we are given a candidate object and must either find a compressed/structured representation of it or determine that none exist. For a particular notion of compressibility, a natural question is whether an efficient algorithm for the compression problem would aide us in the construction of incompressible objects. Consider the following two instances of this question: (1) Does an efficient algorithm for circuit minimization imply efficient constructions of hard truth tables?</p> <p>(2) Does an efficient algorithm for factoring integers imply efficient constructions of large prime numbers?</p> <p>In this work, we connect these kinds of questions to the long-standing challenge of proving space/time tradeoffs for Turing machines, and proving stronger separations between the RAM and 1-tape computation models. In particular, one of our main theorems shows that modest space/time tradeoffs for deterministic exponential time, or separations between basic Turing machine memory models, would imply a positive answer to both (1) and (2). These results apply to the derandomization of a wider class of explicit construction problems, where we have some efficient compression scheme that encodes n-bit strings using n bits, and we aim to construct an n-bit string which cannot be recovered from its encoding.</p> <p>Paper: https://eccc.weizmann.ac.il/report/2022/025/</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="circuits"/><category term="complexity"/><summary type="html"><![CDATA[Oliver Korten]]></summary></entry><entry><title type="html">The Composition Complexity of Majority</title><link href="https://cstheory-georgetown.github.io/blog/2022/victor-lecomte/" rel="alternate" type="text/html" title="The Composition Complexity of Majority"/><published>2022-11-11T15:59:00+00:00</published><updated>2022-11-11T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/victor-lecomte</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/victor-lecomte/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://victorlecomte.com">Victor Lecomte</a> November 11, 2022.</p> <h3 id="abstract">Abstract</h3> <p>In this talk, we’ll look at computing majority as a composition of local functions: Maj_n = h(g_1, …, g_m) where each g_j: {0,1}^n → {0,1} is an arbitrary function that queries only k « n variables, and h: {0,1}^m → {0,1} is an arbitrary combining function. It turns out we need m = Θ(n/k * log k) inner functions, instead of the ideal m = n/k. This recovers as a corollary (and via an entirely different proof) the best known lower bound for bounded-width branching programs for majority. It is also the first step in a plan that we propose for breaking a longstanding barrier in lower bounds for small-depth boolean circuits.</p> <p>Novel aspects of our proof include sharp bounds on the information lost as computation flows through the inner functions g_j, and the bootstrapping of lower bounds for a multi-output function (Hamming weight) into lower bounds for a single-output one (majority).</p> <p>Based on a joint work with Prasanna Ramakrishnan and Li-Yang Tan at Stanford. Paper: https://arxiv.org/pdf/2205.02374.pdf</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="complexity"/><summary type="html"><![CDATA[Victor Lecomte]]></summary></entry><entry><title type="html">Brooks’ Theorem in Graph Streams, A Single-Pass Semi-Streaming Algorithm for Δ-Coloring</title><link href="https://cstheory-georgetown.github.io/blog/2022/parth-mittal/" rel="alternate" type="text/html" title="Brooks’ Theorem in Graph Streams, A Single-Pass Semi-Streaming Algorithm for Δ-Coloring"/><published>2022-10-21T15:59:00+00:00</published><updated>2022-10-21T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/parth-mittal</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/parth-mittal/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://parthmittal.github.io">Parth Mittal</a> October 21, 2022.</p> <h3 id="abstract">Abstract</h3> <p>Every graph with maximum degree Δ can be colored with (Δ+1) colors using a simple greedy algorithm. Remarkably, recent work has shown that one can find such a coloring even in the semi-streaming model. But, in reality, one almost never needs (Δ+1) colors to properly color a graph. Indeed, the celebrated \Brooks’ theorem states that every (connected) graph beside cliques and odd cycles can be colored with Δ colors. Can we find a Δ-coloring in the semi-streaming model as well? We settle this key question in the affirmative by designing a randomized semi-streaming algorithm that given any graph, with high probability, either correctly declares that the graph is not Δ-colorable or outputs a Δ-coloring of the graph. The proof of this result starts with a detour. We first (provably) identify the extent to which the previous approaches for streaming coloring fail for Δ-coloring: for instance, all these approaches can handle streams with repeated edges and they can run in o(n2) time – we prove that neither of these tasks is possible for Δ-coloring. These impossibility results however pinpoint exactly what is missing from prior approaches when it comes to Δ-coloring. We then build on these insights to design a semi-streaming algorithm that uses (i) a novel sparse-recovery approach based on sparse-dense decompositions to (partially) recover the “problematic” subgraphs of the input – the ones that form the basis of our impossibility results – and (ii) a new coloring approach for these subgraphs that allows for recoloring of other vertices in a controlled way without relying on local explorations or finding “augmenting paths” that are generally impossible for semi-streaming algorithms. We believe both these techniques can be of independent interest.</p> <p>Paper: https://arxiv.org/abs/2203.10984</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="streaming"/><category term="algorithms"/><summary type="html"><![CDATA[Parth Mittal]]></summary></entry><entry><title type="html">Limitations of Linear Cross-Entropy as a Measure of Quantum Advantage</title><link href="https://cstheory-georgetown.github.io/blog/2022/chi-ning-chou/" rel="alternate" type="text/html" title="Limitations of Linear Cross-Entropy as a Measure of Quantum Advantage"/><published>2022-09-30T15:59:00+00:00</published><updated>2022-09-30T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/chi-ning-chou</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/chi-ning-chou/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://cnchou.github.io">Chi-Ning Chou</a> September 30, 2022.</p> <h3 id="abstract">Abstract</h3> <p>Quantum advantage is a program aiming to demonstrate the computational advantage of incorporating quantum mechanics in near-term realizable devices. Random Circuits Sampling (RCS) is one of the leading approaches that was adopted by the recent breakthroughs of Google and USTC. Specifically, both of them were using the linear cross-entropy (linear XEB) as a measure to evaluate the computational advantage of their devices. For example, in 2019, Google achieved a score of 0.00224 XEB value using a 53-qubit quantum processor and conjectured that it requires 10,000 years for the best supercomputer to get a similar XEB value.</p> <p>In this talk, I’m going to present our recent work on reexamining the usage of linear XEB as a measure of quantum advantage. I will start with giving a broad overview on the previous developments and formally set up the mathematical formulation. Next, I will state our main theoretical and numerical results and discuss their implications. Finally, if time allows, I will give a bird-eye view on the underlying new mathematical framework we developed for analyzing linear XEB.</p> <p>No background in quantum computation and physics is needed but I will assume a little familiarity with basic linear algebra and probability theory. This is a joint work with Xun Gao, Marcin Kalinowski, Mikhail Lukin, Boaz Barak, and Soonwon Choi. Link to the paper: https://arxiv.org/pdf/2112.01657.pdf.</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="quantum"/><summary type="html"><![CDATA[Chi-Ning Chou]]></summary></entry><entry><title type="html">A better-than-3 log n depth lower bound for De Morgan formulas with restrictions on top gates</title><link href="https://cstheory-georgetown.github.io/blog/2022/anastasia-safronova/" rel="alternate" type="text/html" title="A better-than-3 log n depth lower bound for De Morgan formulas with restrictions on top gates"/><published>2022-09-23T15:59:00+00:00</published><updated>2022-09-23T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/anastasia-safronova</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/anastasia-safronova/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="http://asofronova.com">Anastasia Sofronova</a> Septmber 23,2022.</p> <h3 id="abstract">Abstract</h3> <p>The talk is about a weak variant of Karchmer-Raz-Wigderson conjecture. This is a joint work with Ivan Mihajlin.</p> <p>We prove the existence of two functions f: {0,1}^n → {0,1} and g: {0,1}^n → {0,1}^n such that f(g(x)⊕y) is not computable by depth (1 + α − ε)n formulas with (2α − ε)n layers of AND gates at the top. We do this by a top-down approach, which was only used before for depth-3 model. As an application of the result, we immediately get a simple lower bound on a modified Andreev’s function.</p> <p>Our technical contribution includes combinatorial insights into structure of composition with random boolean function and introducing a notion of well-mixed sets. A set of functions is well-mixed if, when composed with a random function, it does not have subsets that agree on large fractions of inputs. We use probabilistic method to prove the existence of well-mixed sets.</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="complexity"/><summary type="html"><![CDATA[Anastasia Sofronova]]></summary></entry><entry><title type="html">Why we couldn’t prove SETH hardness of CVP for even norms, Subset-SUM, and Many more!</title><link href="https://cstheory-georgetown.github.io/blog/2022/rajendra-kumar/" rel="alternate" type="text/html" title="Why we couldn’t prove SETH hardness of CVP for even norms, Subset-SUM, and Many more!"/><published>2022-09-16T15:59:00+00:00</published><updated>2022-09-16T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/rajendra-kumar</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/rajendra-kumar/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://sites.google.com/view/rajendrak/home">Rajendra Kumar</a> September 16, 2021.</p> <h3 id="abstract">Abstract</h3> <p>Lattice-based cryptographic schemes have generated much interest in recent years. Their security relies on the computational hardness of problems over geometric objects called lattices. These problems have been used to build advanced cryptographic primitives such as fully homomorphic encryption, and they are believed to be resistant to quantum attacks. Given the recent advancement in quantum technologies, many institutes such as the National Institute of Standards and Technology (NIST) and European Telecommunications Standards Institute (ETSI) have initiated a process for standardization and deployment of lattice-based schemes widely over the next few years. Recently, NIST has announced lattice-based candidates (Kyber and Dilithium) as the primary algorithms for implementation.</p> <p>The security of the lattice-based cryptosystem schemes crucially relies on the assumption that the best-known algorithms for the corresponding lattice problems cannot be significantly improved. Understanding the fine-grained hardness of these problems is one way of getting more confidence in these assumptions.</p> <p>In this talk, I will discuss the fine-grained hardness of the lattice problems in different p-norms. Mainly, I will focus on the recent joint work with Divesh Aggarwal. Under a complexity-theoretic assumption, we show that getting any SETH-hardness for the lattice problems in the even norm is impossible by a poly-time reduction from k-SAT to CVP. We also show similar impossibility results for Subset-SUM and many other problems.</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="cryptography"/><category term="fine_grained_hardness"/><summary type="html"><![CDATA[Rajendra Kumar]]></summary></entry><entry><title type="html">Improved Quantum Query Upper Bounds Based on Classical Decision Trees</title><link href="https://cstheory-georgetown.github.io/blog/2022/nikhil-mande/" rel="alternate" type="text/html" title="Improved Quantum Query Upper Bounds Based on Classical Decision Trees"/><published>2022-08-30T15:59:00+00:00</published><updated>2022-08-30T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/nikhil-mande</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/nikhil-mande/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://mande-nikhil.github.io">Nikhil Mande</a> October 30, 2022.</p> <h3 id="abstract">Abstract</h3> <p>In the first part of this talk we will discuss the notion of rank of decision trees, which is essentially the largest depth of a complete subtree embedded in the initial tree. We observe the equivalence of rank and “guessing complexity,” a measure of decision trees used by Lin and Lin [Theory of Computing’16] and Beigi and Taghavi [Quantum’20] to give upper bounds on quantum query complexity of functions based on classical query algorithms for them. In the second part of the talk we will first note that the best speed-up obtainable using the approach of Beigi and Taghavi is captured by a polynomial optimization program on assignments of real weights to edges of the underlying classical decision tree. We then give a recursive expression for the optimal solution to this program and bound the optimum from above in terms of natural measures of the decision tree.</p> <p>Based on joint work with Arjan Cornelissen and Subhasree Patro (https://arxiv.org/abs/2203.02968)</p>]]></content><author><name></name></author><category term="fall-2022"/><category term="cryptography"/><summary type="html"><![CDATA[Nikhil Mande]]></summary></entry><entry><title type="html">Interior Point Methods for Nearly Linear Time Algorithms</title><link href="https://cstheory-georgetown.github.io/blog/2022/aaron-sidford/" rel="alternate" type="text/html" title="Interior Point Methods for Nearly Linear Time Algorithms"/><published>2022-05-13T15:59:00+00:00</published><updated>2022-05-13T15:59:00+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/aaron-sidford</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/aaron-sidford/"><![CDATA[<h3 id="speaker">Speaker</h3> <p><a href="https://web.stanford.edu/~sidford/">Aaron Sidford</a> May 13, 2021.</p> <h3 id="abstract">Abstract</h3> <p>Linear programming is a foundational continuous optimization problem and special cases, e.g. maximum cardinality bipartite matching, are among the most fundamental problems in combinatorial optimization. In this talk, I will survey recent advances in solving these problems using interior point methods. I will discuss how new interior point methods can be leveraged to efficiently reduce these problems to data structures problems which can be solved efficiently with techniques from randomized numerical linear algebra and graph theory. This talk will highlight recent joint work which showed that linear programs with d variables and n constraints can be solved with high probability to high precision in time Otilde(nd + poly(d)) and that a variety of graph problems, e.g. maximum flow and optimal transport, on n-node -m-edge graphs can be solved to with high probability to high precision in time Otilde(m + n^1.5). No previous experience with interior point methods required.</p>]]></content><author><name></name></author><category term="spring-2022"/><category term="algorithms"/><summary type="html"><![CDATA[Aaron Sidford]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://cstheory-georgetown.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://cstheory-georgetown.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://cstheory-georgetown.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>